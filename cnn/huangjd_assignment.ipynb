{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.12"},"colab":{"name":"Copy of assignment.ipynb","provenance":[{"file_id":"https://github.com/peterchang77/dl_tutor/blob/master/cs190/spring_2021/notebooks/cnn/assignment.ipynb","timestamp":1618603226411}]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"dLGD0gxzUh9D"},"source":["# Assignment\n","\n","In this assignment we will train a convolutional neural network (CNN) on the CIFAR-10 dataset.\n","\n","This assignment is part of the class **Introduction to Deep Learning for Medical Imaging** at University of California Irvine (CS190); more information can be found: https://github.com/peterchang77/dl_tutor/tree/master/cs190."]},{"cell_type":"markdown","metadata":{"id":"vbIQojq0Uh9M"},"source":["### Submission\n","\n","Once complete, the following items must be submitted:\n","\n","* final `*.ipynb` notebook (push to https://github.com/[username]/cs190/cnn/assignment.ipynb)\n","* final trained `*.hdf5` model file\n","* final compiled `*.csv` file with performance statistics"]},{"cell_type":"markdown","metadata":{"id":"56d3oMiMw8Wm"},"source":["# Google Colab"]},{"cell_type":"markdown","metadata":{"id":"jEnv4o8yUh9N"},"source":["### Enable GPU runtime\n","\n","Use the following instructions to switch the default Colab instance into a GPU-enabled runtime:\n","\n","```\n","Runtime > Change runtime type > Hardware accelerator > GPU\n","```"]},{"cell_type":"markdown","metadata":{"id":"76lTqALkUh9N"},"source":["# Environment"]},{"cell_type":"markdown","metadata":{"id":"VXbHCeQcUh9N"},"source":["### Jarvis library\n","\n","In this notebook we will Jarvis, a custom Python package to facilitate data science and deep learning for healthcare. Among other things, this library will be used for low-level data management, stratification and visualization of high-dimensional medical data."]},{"cell_type":"code","metadata":{"id":"8OUTb23NUh9O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618699675871,"user_tz":420,"elapsed":4106,"user":{"displayName":"Jared Huang","photoUrl":"","userId":"08976591547548060713"}},"outputId":"97ec13a8-98f4-4c1c-c175-cd6776ab76fc"},"source":["# --- Install jarvis (only in Google Colab or local runtime)\n","% pip install jarvis-md"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting jarvis-md\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/ff/f1dd393248444d78c721d8f086a417ac0d8407892aafd8fd3e64a2088755/jarvis_md-0.0.1a12-py3-none-any.whl (74kB)\n","\r\u001b[K     |████▍                           | 10kB 21.2MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 20kB 15.1MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 30kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 40kB 11.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 51kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 61kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 71kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 5.3MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.1.5)\n","Collecting pyyaml>=5.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n","\u001b[K     |████████████████████████████████| 645kB 10.8MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.4.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (2.23.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (2.10.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.19.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (3.2.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->jarvis-md) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->jarvis-md) (2.8.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (2020.12.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->jarvis-md) (1.15.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (2.4.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (1.3.1)\n","Installing collected packages: pyyaml, jarvis-md\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed jarvis-md-0.0.1a12 pyyaml-5.4.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5HrRjTy_Uh9P"},"source":["### Imports\n","\n","Use the following lines to import any additional needed libraries:"]},{"cell_type":"code","metadata":{"id":"as9zqGPDUh9P","executionInfo":{"status":"ok","timestamp":1618699677391,"user_tz":420,"elapsed":5606,"user":{"displayName":"Jared Huang","photoUrl":"","userId":"08976591547548060713"}}},"source":["import os, numpy as np, pandas as pd\n","from tensorflow import losses, optimizers\n","from tensorflow.keras import Input, Model, models, layers\n","from jarvis.train import datasets\n","from tensorflow.keras import regularizers"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TLB458iBUh9Q"},"source":["# Data\n","\n","As in the tutorial, data for this assignment will consist of the CIFAR-10 dataset comprising 10 different everyday objects (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck). The following lines of code will:\n","\n","1. Download the dataset (if not already present) \n","2. Prepare the necessary Python generators to iterate through dataset\n","3. Prepare the corresponding Tensorflow Input(...) objects for model definition"]},{"cell_type":"code","metadata":{"id":"zQkET-9tUh9Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618699694743,"user_tz":420,"elapsed":10751,"user":{"displayName":"Jared Huang","photoUrl":"","userId":"08976591547548060713"}},"outputId":"2b16b39c-5a7c-4014-b477-567c88051d77"},"source":["# --- Download dataset\n","datasets.download(name='cifar')\n","\n","# --- Prepare generators and model inputs\n","gen_train, gen_valid, client = datasets.prepare(name='cifar')\n","inputs = client.get_inputs(Input)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[ 2021-04-17 22:48:12 ] [====================] 100.000% : Iterating | 000001    "],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wpUk0_FFUh9Q"},"source":["# Training\n","\n","In this assignment we will train a basic convolutional neural network on the CIFAR-10 dataset. At minumum you must include the following baseline techniques covered in the tutorial:\n","\n","* convolutional operations\n","* batch normalization\n","* activation function\n","* subsampling\n","\n","You are also **encouraged** to try different permuations and customizations to achieve optimal validation accuracy."]},{"cell_type":"markdown","metadata":{"id":"XT_9TQ08Uh9R"},"source":["### Define the model"]},{"cell_type":"code","metadata":{"id":"L9jcYVTCUh9R","executionInfo":{"status":"ok","timestamp":1618699710206,"user_tz":420,"elapsed":5771,"user":{"displayName":"Jared Huang","photoUrl":"","userId":"08976591547548060713"}}},"source":["inputs = {}\n","inputs['dat'] = Input(shape=(32,32,3))\n","\n","kwargs = {\n","    'kernel_size': (3, 3),\n","    'padding': 'same', \n","    'kernel_regularizer' : regularizers.l2(0.01)}\n","\n","conv = lambda x, filters, strides : layers.Conv2D(filters=filters, strides=strides, **kwargs)(x)\n","norm = lambda x : layers.BatchNormalization()(x)\n","relu = lambda x : layers.ReLU()(x)\n","\n","pool2 = lambda x : layers.MaxPooling2D(pool_size=(2, 2), strides = (2, 2))(x)\n","# pool2 = lambda x : layers.MaxPooling2D(pool_size=(2, 2))(x)\n","\n","conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n","conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=(2, 2))))\n","\n","drop = layers.Dropout(rate=0.25)\n","\n","# l1 = conv1(16, inputs['dat'])\n","# l2 = conv1(16, l1)\n","# l3 = pool2(l2)\n","# l4 = drop(l3)\n","# l5 = conv1(32, l4)\n","# l6 = conv1(32, l5)\n","# l7 = conv2(32, l6)\n","# l8 = drop(l7)\n","# l9 = conv1(64, l8)\n","# l10 = conv1(64, l9)\n","# l11 = pool2(l10)\n","\n","l1 = conv1(32, inputs['dat'])\n","l2 = conv1(32, l1)\n","l3 = pool2(l2)\n","l4 = drop(l3)\n","l5 = conv1(64, l4)\n","l6 = conv1(64, l5)\n","l7 = pool2(l6)\n","\n","f0 = layers.Flatten()(l7)\n","# f0 = layers.Conv2D(filters=48, kernel_size = (4,4), strides=(1,1), padding='valid')(l4)\n","f1 = drop(f0)\n","f2 = layers.Dense(128, activation='relu')(f1)\n","\n","logits = {}\n","logits['class'] = layers.Dense(10, name='class')(f2)\n","\n","# --- Create model\n","model = Model(inputs=inputs, outputs=logits)"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_HEDHTtHUh9R"},"source":["### Compile the model"]},{"cell_type":"code","metadata":{"id":"my1WxZ5TUh9S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618699710209,"user_tz":420,"elapsed":2528,"user":{"displayName":"Jared Huang","photoUrl":"","userId":"08976591547548060713"}},"outputId":"d157be32-1446-41e8-8da1-68934a9f44fd"},"source":["# --- Compile model\n","model.compile(\n","    optimizer=optimizers.Adam(learning_rate=2e-4), \n","    loss={'class': losses.SparseCategoricalCrossentropy(from_logits=True)}, \n","    metrics={'class': 'sparse_categorical_accuracy'})\n","\n","model.summary()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 32, 32, 32)   896         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 32, 32, 32)   128         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","re_lu (ReLU)                    (None, 32, 32, 32)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 32, 32, 32)   9248        re_lu[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 32, 32, 32)   128         conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","re_lu_1 (ReLU)                  (None, 32, 32, 32)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 16, 16, 32)   0           re_lu_1[0][0]                    \n","__________________________________________________________________________________________________\n","dropout (Dropout)               multiple             0           max_pooling2d[0][0]              \n","                                                                 flatten[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 16, 16, 64)   18496       dropout[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 16, 16, 64)   256         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","re_lu_2 (ReLU)                  (None, 16, 16, 64)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 16, 16, 64)   36928       re_lu_2[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 16, 16, 64)   256         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","re_lu_3 (ReLU)                  (None, 16, 16, 64)   0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 64)     0           re_lu_3[0][0]                    \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 4096)         0           max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 128)          524416      dropout[1][0]                    \n","__________________________________________________________________________________________________\n","class (Dense)                   (None, 10)           1290        dense[0][0]                      \n","==================================================================================================\n","Total params: 592,042\n","Trainable params: 591,658\n","Non-trainable params: 384\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"waAW-8KLUh9S"},"source":["### Train the model"]},{"cell_type":"code","metadata":{"id":"0TqvFoc3Uh9T","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618700292533,"user_tz":420,"elapsed":580021,"user":{"displayName":"Jared Huang","photoUrl":"","userId":"08976591547548060713"}},"outputId":"cf42c088-5789-42ca-9902-edca8f674e42"},"source":["model.fit(\n","    x=gen_train, \n","    steps_per_epoch=750, \n","    epochs=20,\n","    validation_data=gen_valid,\n","    validation_steps=750,\n","    validation_freq=4)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","750/750 [==============================] - 56s 30ms/step - loss: 3.3022 - sparse_categorical_accuracy: 0.3186\n","Epoch 2/20\n","750/750 [==============================] - 23s 30ms/step - loss: 2.4014 - sparse_categorical_accuracy: 0.4898\n","Epoch 3/20\n","750/750 [==============================] - 23s 30ms/step - loss: 1.9041 - sparse_categorical_accuracy: 0.5702\n","Epoch 4/20\n","750/750 [==============================] - 42s 56ms/step - loss: 1.6225 - sparse_categorical_accuracy: 0.6066 - val_loss: 1.4527 - val_sparse_categorical_accuracy: 0.6398\n","Epoch 5/20\n","750/750 [==============================] - 23s 30ms/step - loss: 1.4016 - sparse_categorical_accuracy: 0.6483\n","Epoch 6/20\n","750/750 [==============================] - 23s 31ms/step - loss: 1.3014 - sparse_categorical_accuracy: 0.6577\n","Epoch 7/20\n","750/750 [==============================] - 23s 31ms/step - loss: 1.1866 - sparse_categorical_accuracy: 0.6788\n","Epoch 8/20\n","750/750 [==============================] - 41s 55ms/step - loss: 1.1387 - sparse_categorical_accuracy: 0.6836 - val_loss: 1.1843 - val_sparse_categorical_accuracy: 0.6650\n","Epoch 9/20\n","750/750 [==============================] - 23s 31ms/step - loss: 1.0265 - sparse_categorical_accuracy: 0.7171\n","Epoch 10/20\n","750/750 [==============================] - 23s 30ms/step - loss: 1.0369 - sparse_categorical_accuracy: 0.7021\n","Epoch 11/20\n","750/750 [==============================] - 23s 30ms/step - loss: 0.9557 - sparse_categorical_accuracy: 0.7292\n","Epoch 12/20\n","750/750 [==============================] - 41s 54ms/step - loss: 0.9474 - sparse_categorical_accuracy: 0.7216 - val_loss: 1.0509 - val_sparse_categorical_accuracy: 0.6950\n","Epoch 13/20\n","750/750 [==============================] - 23s 30ms/step - loss: 0.9098 - sparse_categorical_accuracy: 0.7388\n","Epoch 14/20\n","750/750 [==============================] - 23s 30ms/step - loss: 0.9007 - sparse_categorical_accuracy: 0.7417\n","Epoch 15/20\n","750/750 [==============================] - 23s 30ms/step - loss: 0.8310 - sparse_categorical_accuracy: 0.7560\n","Epoch 16/20\n","750/750 [==============================] - 41s 55ms/step - loss: 0.8615 - sparse_categorical_accuracy: 0.7386 - val_loss: 0.9189 - val_sparse_categorical_accuracy: 0.7286\n","Epoch 17/20\n","750/750 [==============================] - 23s 30ms/step - loss: 0.8034 - sparse_categorical_accuracy: 0.7663\n","Epoch 18/20\n","750/750 [==============================] - 23s 30ms/step - loss: 0.8211 - sparse_categorical_accuracy: 0.7568\n","Epoch 19/20\n","750/750 [==============================] - 23s 30ms/step - loss: 0.7833 - sparse_categorical_accuracy: 0.7722\n","Epoch 20/20\n","750/750 [==============================] - 41s 54ms/step - loss: 0.8156 - sparse_categorical_accuracy: 0.7558 - val_loss: 0.8734 - val_sparse_categorical_accuracy: 0.7400\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f4dd4ee32d0>"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"vvgdwHlp8vpb","executionInfo":{"status":"ok","timestamp":1618700389687,"user_tz":420,"elapsed":313,"user":{"displayName":"Jared Huang","photoUrl":"","userId":"08976591547548060713"}}},"source":["model.save('./cnn.hdf5')\n","\n","# del model\n","# model = models.load_model('./cnn.hdf5', compile=False)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"4SypUJulRolp","executionInfo":{"status":"ok","timestamp":1618700556813,"user_tz":420,"elapsed":434,"user":{"displayName":"Jared Huang","photoUrl":"","userId":"08976591547548060713"}}},"source":["model = models.load_model('./cnn.hdf5', compile=False)"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Vh53BCMUh9T"},"source":["# Evaluation\n","\n","Based on the tutorial discussion, use the following cells to check your algorithm performance. Consider loading a saved model and running prediction using `model.predict(...)` on the data aggregated via a test generator."]},{"cell_type":"code","metadata":{"id":"oyGgasNkUh9U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618700577689,"user_tz":420,"elapsed":19328,"user":{"displayName":"Jared Huang","photoUrl":"","userId":"08976591547548060713"}},"outputId":"02ce9ebc-dfd1-4a6c-8132-ba984c7eff19"},"source":["# --- Create validation generator\n","test_train, test_valid = client.create_generators(test=True)\n","\n","# --- Aggregate all examples\n","xs = []\n","ys = []\n","\n","# use test generator so you don't run infintely \n","for x, y in test_valid:\n","    xs.append(x['dat'])\n","    ys.append(y['class'])\n","\n","xs = np.concatenate(xs)\n","ys = np.concatenate(ys)\n","\n","# --- Predict\n","logits = model.predict(xs)\n","\n","if type(logits) is dict:\n","    logits = logits['class']\n","\n","# --- Argmax\n","pred = np.argmax(logits, axis=1)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[ 2021-04-17 23:02:56 ] [====================] 100.000% : Iterating | 012000    "],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SqXRBZ2wUh9U"},"source":["**Note**: this cell is used only to check for model performance. It will not be graded. Once you are satisfied with your model, proceed to submission of your assignment below."]},{"cell_type":"markdown","metadata":{"id":"pYyDk1pmUh9U"},"source":["### Results\n","\n","When ready, create a `*.csv` file with your compiled **validation** cohort statistics. There is no need to submit training performance accuracy. As in the tutorial, ensure that there are at least three columns in the `*.csv` file:\n","\n","* true (ground-truth)\n","* pred (prediction)\n","* corr (correction prediction, True or False)"]},{"cell_type":"code","metadata":{"id":"s8SbBtue89_V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618700578422,"user_tz":420,"elapsed":265,"user":{"displayName":"Jared Huang","photoUrl":"","userId":"08976591547548060713"}},"outputId":"bd63d820-b517-4335-bcb1-e3079e6cc5e3"},"source":["# --- Create *.csv\n","df = pd.DataFrame(index=np.arange(pred.size))\n","\n","# --- Define columns\n","df['true'] = ys[:, 0]\n","df['pred'] = pred\n","df['corr'] = df['true'] == df['pred']\n","\n","# --- Print accuracy\n","print(df['corr'].mean())"],"execution_count":10,"outputs":[{"output_type":"stream","text":["0.73975\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Tk0pFBbSUh9U","executionInfo":{"status":"ok","timestamp":1618700583291,"user_tz":420,"elapsed":275,"user":{"displayName":"Jared Huang","photoUrl":"","userId":"08976591547548060713"}}},"source":["\n","MOUNT_ROOT = './gdrive/MyDrive'\n","                              \n","# --- Serialize *.csv\n","fname = '{}/models/cnn/results.csv'.format(MOUNT_ROOT)\n","os.makedirs(os.path.dirname(fname), exist_ok=True)\n","df.to_csv(fname)"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dw8NNbOIUh9V"},"source":["# Submission\n","\n","Use the following line to save your model for submission:"]},{"cell_type":"code","metadata":{"id":"Wccx55EaUh9V"},"source":["# --- Serialize a model\n","model.save('./cnn.hdf5')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"spglPvPZUh9W"},"source":["### Canvas\n","\n","Once you have completed this assignment, download the necessary files from Google Colab and your Google Drive. You will then need to submit the following items:\n","\n","* final (completed) notebook: `[UCInetID]_assignment.ipynb`\n","* final (results) spreadsheet: `[UCInetID]_results.csv`\n","* final (trained) model: `[UCInetID]_model.hdf5`\n","\n","**Important**: please submit all your files prefixed with your UCInetID as listed above. Your UCInetID is the part of your UCI email address that comes before `@uci.edu`. For example, Peter Anteater has an email address of panteater@uci.edu, so his notebooke file would be submitted under the name `panteater_notebook.ipynb`, his spreadshhet would be submitted under the name `panteater_results.csv` and and his model file would be submitted under the name `panteater_model.hdf5`."]}]}