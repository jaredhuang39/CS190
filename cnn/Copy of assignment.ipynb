{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.12"},"colab":{"name":"Copy of assignment.ipynb","provenance":[{"file_id":"https://github.com/peterchang77/dl_tutor/blob/master/cs190/spring_2021/notebooks/cnn/assignment.ipynb","timestamp":1618603226411}],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"dLGD0gxzUh9D"},"source":["# Assignment\n","\n","In this assignment we will train a convolutional neural network (CNN) on the CIFAR-10 dataset.\n","\n","This assignment is part of the class **Introduction to Deep Learning for Medical Imaging** at University of California Irvine (CS190); more information can be found: https://github.com/peterchang77/dl_tutor/tree/master/cs190."]},{"cell_type":"markdown","metadata":{"id":"vbIQojq0Uh9M"},"source":["### Submission\n","\n","Once complete, the following items must be submitted:\n","\n","* final `*.ipynb` notebook (push to https://github.com/[username]/cs190/cnn/assignment.ipynb)\n","* final trained `*.hdf5` model file\n","* final compiled `*.csv` file with performance statistics"]},{"cell_type":"markdown","metadata":{"id":"56d3oMiMw8Wm"},"source":["# Google Colab"]},{"cell_type":"markdown","metadata":{"id":"jEnv4o8yUh9N"},"source":["### Enable GPU runtime\n","\n","Use the following instructions to switch the default Colab instance into a GPU-enabled runtime:\n","\n","```\n","Runtime > Change runtime type > Hardware accelerator > GPU\n","```"]},{"cell_type":"markdown","metadata":{"id":"76lTqALkUh9N"},"source":["# Environment"]},{"cell_type":"markdown","metadata":{"id":"VXbHCeQcUh9N"},"source":["### Jarvis library\n","\n","In this notebook we will Jarvis, a custom Python package to facilitate data science and deep learning for healthcare. Among other things, this library will be used for low-level data management, stratification and visualization of high-dimensional medical data."]},{"cell_type":"code","metadata":{"id":"8OUTb23NUh9O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618603288173,"user_tz":420,"elapsed":3769,"user":{"displayName":"Jared Huang","photoUrl":"","userId":"08976591547548060713"}},"outputId":"0ecea3e8-145b-4c15-f29a-d72d2f6b1697"},"source":["# --- Install jarvis (only in Google Colab or local runtime)\n","% pip install jarvis-md"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting jarvis-md\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/ff/f1dd393248444d78c721d8f086a417ac0d8407892aafd8fd3e64a2088755/jarvis_md-0.0.1a12-py3-none-any.whl (74kB)\n","\r\u001b[K     |████▍                           | 10kB 21.9MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 20kB 21.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 30kB 17.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 40kB 14.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 51kB 17.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 61kB 17.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 71kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 7.7MB/s \n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.4.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (3.2.2)\n","Collecting pyyaml>=5.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n","\u001b[K     |████████████████████████████████| 645kB 38.1MB/s \n","\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (2.10.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (2.23.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.1.5)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from jarvis-md) (1.19.5)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->jarvis-md) (1.3.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->jarvis-md) (1.15.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->jarvis-md) (2.10)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->jarvis-md) (2018.9)\n","Installing collected packages: pyyaml, jarvis-md\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed jarvis-md-0.0.1a12 pyyaml-5.4.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5HrRjTy_Uh9P"},"source":["### Imports\n","\n","Use the following lines to import any additional needed libraries:"]},{"cell_type":"code","metadata":{"id":"as9zqGPDUh9P","executionInfo":{"status":"ok","timestamp":1618603292815,"user_tz":420,"elapsed":1702,"user":{"displayName":"Jared Huang","photoUrl":"","userId":"08976591547548060713"}}},"source":["import os, numpy as np, pandas as pd\n","from tensorflow import losses, optimizers\n","from tensorflow.keras import Input, Model, models, layers\n","from jarvis.train import datasets\n","from tensorflow.keras import regularizers"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TLB458iBUh9Q"},"source":["# Data\n","\n","As in the tutorial, data for this assignment will consist of the CIFAR-10 dataset comprising 10 different everyday objects (airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck). The following lines of code will:\n","\n","1. Download the dataset (if not already present) \n","2. Prepare the necessary Python generators to iterate through dataset\n","3. Prepare the corresponding Tensorflow Input(...) objects for model definition"]},{"cell_type":"code","metadata":{"id":"zQkET-9tUh9Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618603301573,"user_tz":420,"elapsed":8290,"user":{"displayName":"Jared Huang","photoUrl":"","userId":"08976591547548060713"}},"outputId":"62905829-4720-4bf7-e2d6-8467d780b6c3"},"source":["# --- Download dataset\n","datasets.download(name='cifar')\n","\n","# --- Prepare generators and model inputs\n","gen_train, gen_valid, client = datasets.prepare(name='cifar')\n","inputs = client.get_inputs(Input)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[ 2021-04-16 20:01:39 ] [====================] 100.000% : Iterating | 000001    "],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wpUk0_FFUh9Q"},"source":["# Training\n","\n","In this assignment we will train a basic convolutional neural network on the CIFAR-10 dataset. At minumum you must include the following baseline techniques covered in the tutorial:\n","\n","* convolutional operations\n","* batch normalization\n","* activation function\n","* subsampling\n","\n","You are also **encouraged** to try different permuations and customizations to achieve optimal validation accuracy."]},{"cell_type":"markdown","metadata":{"id":"XT_9TQ08Uh9R"},"source":["### Define the model"]},{"cell_type":"code","metadata":{"id":"L9jcYVTCUh9R","executionInfo":{"status":"ok","timestamp":1618603477286,"user_tz":420,"elapsed":5709,"user":{"displayName":"Jared Huang","photoUrl":"","userId":"08976591547548060713"}}},"source":["inputs = {}\n","inputs['dat'] = Input(shape=(32,32,3))\n","\n","kwargs = {\n","    'kernel_size': (3, 3),\n","    'padding': 'same', \n","    'kernel_regularizer' : regularizers.l2(0.01)}\n","\n","conv = lambda x, filters, strides : layers.Conv2D(filters=filters, strides=strides, **kwargs)(x)\n","norm = lambda x : layers.BatchNormalization()(x)\n","relu = lambda x : layers.ReLU()(x)\n","\n","pool2 = lambda x : layers.MaxPooling2D(pool_size=(2, 2), strides = (2, 2))(x)\n","# pool2 = lambda x : layers.MaxPooling2D(pool_size=(2, 2))(x)\n","\n","conv1 = lambda filters, x : relu(norm(conv(x, filters, strides=1)))\n","conv2 = lambda filters, x : relu(norm(conv(x, filters, strides=(2, 2))))\n","\n","drop = layers.Dropout(rate=0.25)\n","\n","# l1 = conv1(16, inputs['dat'])\n","# l2 = conv1(16, l1)\n","# l3 = pool2(l2)\n","# l4 = drop(l3)\n","# l5 = conv1(32, l4)\n","# l6 = conv1(32, l5)\n","# l7 = conv2(32, l6)\n","# l8 = drop(l7)\n","# l9 = conv1(64, l8)\n","# l10 = conv1(64, l9)\n","# l11 = pool2(l10)\n","\n","l1 = conv1(32, inputs['dat'])\n","l2 = conv1(32, l1)\n","l3 = pool2(l2)\n","l4 = drop(l3)\n","l5 = conv1(64, l4)\n","l6 = conv1(64, l5)\n","l7 = pool2(l6)\n","\n","f0 = layers.Flatten()(l7)\n","# f0 = layers.Conv2D(filters=48, kernel_size = (4,4), strides=(1,1), padding='valid')(l4)\n","f1 = drop(f0)\n","f2 = layers.Dense(128, activation='relu')(f1)\n","\n","logits = {}\n","logits['class'] = layers.Dense(10, name='class')(f2)\n","\n","# --- Create model\n","model = Model(inputs=inputs, outputs=logits)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_HEDHTtHUh9R"},"source":["### Compile the model"]},{"cell_type":"code","metadata":{"id":"my1WxZ5TUh9S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618603519135,"user_tz":420,"elapsed":271,"user":{"displayName":"Jared Huang","photoUrl":"","userId":"08976591547548060713"}},"outputId":"e16d637c-cbfd-4b51-ca27-a97996fe66c1"},"source":["# --- Compile model\n","model.compile(\n","    optimizer=optimizers.Adam(learning_rate=2e-4), \n","    loss={'class': losses.SparseCategoricalCrossentropy(from_logits=True)}, \n","    metrics={'class': 'sparse_categorical_accuracy'})\n","\n","model.summary()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n","__________________________________________________________________________________________________\n","conv2d (Conv2D)                 (None, 32, 32, 32)   896         input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, 32, 32, 32)   128         conv2d[0][0]                     \n","__________________________________________________________________________________________________\n","re_lu (ReLU)                    (None, 32, 32, 32)   0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 32, 32, 32)   9248        re_lu[0][0]                      \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, 32, 32, 32)   128         conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","re_lu_1 (ReLU)                  (None, 32, 32, 32)   0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d (MaxPooling2D)    (None, 16, 16, 32)   0           re_lu_1[0][0]                    \n","__________________________________________________________________________________________________\n","dropout (Dropout)               multiple             0           max_pooling2d[0][0]              \n","                                                                 flatten[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 16, 16, 64)   18496       dropout[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, 16, 16, 64)   256         conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","re_lu_2 (ReLU)                  (None, 16, 16, 64)   0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 16, 16, 64)   36928       re_lu_2[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 16, 16, 64)   256         conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","re_lu_3 (ReLU)                  (None, 16, 16, 64)   0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 8, 8, 64)     0           re_lu_3[0][0]                    \n","__________________________________________________________________________________________________\n","flatten (Flatten)               (None, 4096)         0           max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 128)          524416      dropout[1][0]                    \n","__________________________________________________________________________________________________\n","class (Dense)                   (None, 10)           1290        dense[0][0]                      \n","==================================================================================================\n","Total params: 592,042\n","Trainable params: 591,658\n","Non-trainable params: 384\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"waAW-8KLUh9S"},"source":["### Train the model"]},{"cell_type":"code","metadata":{"id":"0TqvFoc3Uh9T","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6de5d363-d814-49ce-bc99-930b4cae3162"},"source":["model.fit(\n","    x=gen_train, \n","    steps_per_epoch=750, \n","    epochs=20,\n","    validation_data=gen_valid,\n","    validation_steps=750,\n","    validation_freq=4)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","750/750 [==============================] - 53s 26ms/step - loss: 3.3018 - sparse_categorical_accuracy: 0.3082\n","Epoch 2/20\n","750/750 [==============================] - 20s 27ms/step - loss: 2.3737 - sparse_categorical_accuracy: 0.4903\n","Epoch 3/20\n","750/750 [==============================] - 20s 27ms/step - loss: 1.8985 - sparse_categorical_accuracy: 0.5711\n","Epoch 4/20\n","750/750 [==============================] - 36s 48ms/step - loss: 1.6053 - sparse_categorical_accuracy: 0.6090 - val_loss: 1.4946 - val_sparse_categorical_accuracy: 0.6188\n","Epoch 5/20\n","750/750 [==============================] - 20s 27ms/step - loss: 1.3976 - sparse_categorical_accuracy: 0.6495\n","Epoch 6/20\n","362/750 [=============>................] - ETA: 10s - loss: 1.2952 - sparse_categorical_accuracy: 0.6559"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vvgdwHlp8vpb"},"source":["model.save('./cnn.hdf5')\n","\n","# del model\n","# model = models.load_model('./cnn.hdf5', compile=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":307},"id":"4SypUJulRolp","executionInfo":{"status":"error","timestamp":1618603318768,"user_tz":420,"elapsed":437,"user":{"displayName":"Jared Huang","photoUrl":"","userId":"08976591547548060713"}},"outputId":"33c4aec6-e205-4dc6-bd50-8834c0611fcf"},"source":["model = models.load_model('./cnn.hdf5', compile=False)"],"execution_count":4,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-081c4c2d401c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./cnn.hdf5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    112\u001b[0m                   (export_dir,\n\u001b[1;32m    113\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: ./cnn.hdf5/{saved_model.pbtxt|saved_model.pb}"]}]},{"cell_type":"markdown","metadata":{"id":"-Vh53BCMUh9T"},"source":["# Evaluation\n","\n","Based on the tutorial discussion, use the following cells to check your algorithm performance. Consider loading a saved model and running prediction using `model.predict(...)` on the data aggregated via a test generator."]},{"cell_type":"code","metadata":{"id":"oyGgasNkUh9U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618602946648,"user_tz":420,"elapsed":17415,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"23dacc2a-98be-48a9-db9d-807873efe84e"},"source":["# --- Create validation generator\n","test_train, test_valid = client.create_generators(test=True)\n","\n","# --- Aggregate all examples\n","xs = []\n","ys = []\n","\n","# use test generator so you don't run infintely \n","for x, y in test_valid:\n","    xs.append(x['dat'])\n","    ys.append(y['class'])\n","\n","xs = np.concatenate(xs)\n","ys = np.concatenate(ys)\n","\n","# --- Predict\n","logits = model.predict(xs)\n","\n","if type(logits) is dict:\n","    logits = logits['class']\n","\n","# --- Argmax\n","pred = np.argmax(logits, axis=1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[ 2021-04-16 19:55:45 ] [====================] 100.000% : Iterating | 012000    "],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SqXRBZ2wUh9U"},"source":["**Note**: this cell is used only to check for model performance. It will not be graded. Once you are satisfied with your model, proceed to submission of your assignment below."]},{"cell_type":"markdown","metadata":{"id":"pYyDk1pmUh9U"},"source":["### Results\n","\n","When ready, create a `*.csv` file with your compiled **validation** cohort statistics. There is no need to submit training performance accuracy. As in the tutorial, ensure that there are at least three columns in the `*.csv` file:\n","\n","* true (ground-truth)\n","* pred (prediction)\n","* corr (correction prediction, True or False)"]},{"cell_type":"code","metadata":{"id":"s8SbBtue89_V","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618602966730,"user_tz":420,"elapsed":257,"user":{"displayName":"","photoUrl":"","userId":""}},"outputId":"a9e25ffb-a8f5-4b3b-a82a-c277f0c264f6"},"source":["# --- Create *.csv\n","df = pd.DataFrame(index=np.arange(pred.size))\n","\n","# --- Define columns\n","df['true'] = ys[:, 0]\n","df['pred'] = pred\n","df['corr'] = df['true'] == df['pred']\n","\n","# --- Print accuracy\n","print(df['corr'].mean())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.7346666666666667\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Tk0pFBbSUh9U"},"source":["\n","MOUNT_ROOT = './gdrive/MyDrive'\n","                              \n","# --- Serialize *.csv\n","fname = '{}/models/cnn/results.csv'.format(MOUNT_ROOT)\n","os.makedirs(os.path.dirname(fname), exist_ok=True)\n","df.to_csv(fname)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dw8NNbOIUh9V"},"source":["# Submission\n","\n","Use the following line to save your model for submission:"]},{"cell_type":"code","metadata":{"id":"Wccx55EaUh9V"},"source":["# --- Serialize a model\n","model.save('./cnn.hdf5')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"spglPvPZUh9W"},"source":["### Canvas\n","\n","Once you have completed this assignment, download the necessary files from Google Colab and your Google Drive. You will then need to submit the following items:\n","\n","* final (completed) notebook: `[UCInetID]_assignment.ipynb`\n","* final (results) spreadsheet: `[UCInetID]_results.csv`\n","* final (trained) model: `[UCInetID]_model.hdf5`\n","\n","**Important**: please submit all your files prefixed with your UCInetID as listed above. Your UCInetID is the part of your UCI email address that comes before `@uci.edu`. For example, Peter Anteater has an email address of panteater@uci.edu, so his notebooke file would be submitted under the name `panteater_notebook.ipynb`, his spreadshhet would be submitted under the name `panteater_results.csv` and and his model file would be submitted under the name `panteater_model.hdf5`."]}]}